<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title> Dynamic scheduling crawler for FeedPusher | TaoAlpha's Blog</title><meta name="description" content="Here is my new blog based on hexo."><meta name="viewport" content="width=device-width, initial-scale=1"><!-- open graph part--><meta property="og:image" content="http://taoalpha.me/images/newblog.jpg"><meta property="og:description" content="TaoAlpha's hexo Blog"><meta property="og:type" content="website"><link rel="short icon" href="/blog/favicon.png"><link rel="stylesheet" href="/blog/css/default.css"></head><body class="blogpost"><aside class="home-menu"><nav class="home-icon-con upside"></nav><a href="/blog/" class="home-menu-icon brand active">涛</a><a href="/blog/tipme" class="home-menu-icon"><i class="fa fa-1x fa-gratipay"></i></a><a href="javascript:$('.searchbox').focus().css('border', '4px dashed #666');setTimeout(function(){$('.searchbox').focus().css('border', 'none').css('border-bottom', '1px solid #ccc')},1000);" class="home-menu-icon"><i class="fa fa-1x fa-search"></i></a><a href="/blog/puzzle" class="home-menu-icon"><i class="fa fa-1x fa-puzzle-piece"></i></a><a href="javascript:;" title="Contact Me" class="home-menu-icon follow">+</a><div class="home-contact"><a href="http://facebook.com/zzgary/" target="something"><img src="https://cdn1.iconfinder.com/data/icons/social-shade-rounded-rects/512/facebook-32.png" alt="facebook"></a><a href="http://github.com/taoalpha/" target="something"><img src="https://cdn1.iconfinder.com/data/icons/social-shade-rounded-rects/512/github-32.png" alt="github"></a><a href="http://taoalpha.me" target="something"><img src="https://cdn3.iconfinder.com/data/icons/colore-sociale/32/mewally_32x32.png" alt="portfolio"></a><a href="http://douban.com/people/129154019" target="something"><img src="http://img3.douban.com/favicon.ico" alt="douban"></a></div><nav class="home-icon-con downside"><a href="#contribution" class="home-menu-icon makecontribution"><i class="fa fa-pencil fa-1x"></i></a><a id="togglemusic" href="javascript:;" class="home-menu-icon"><i class="fa fa-music fa-1x"></i></a></nav><div id="musicbar"><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="298" height="40" src=""></iframe></div></aside><div id="contribution" class="hide"><span class="close"></span><input id="sender_mail" type="email" placeholder="Give me your email"><textarea id="contributionContent" name="contribution" cols="30" rows="10" placeholder="Thanks for your contribution!  Now tell me what you want to say: feedback ? advice ? contributions ? Whatever you want ^_^.  I will look at it as soon as I receive it and reply you asap.  "></textarea><input id="sendToMe" type="submit"></div><article id="content"><section class="entry"><h1 class="entry-title"><a href="http://taoalpha.me/blog/2016/01/12/tech-dynamic-scheduling-crawler-for-feedpusher/" title="Dynamic scheduling crawler for FeedPusher">Dynamic scheduling crawler for FeedPusher</a></h1><div class="meta-top"><a href="http://taoalpha.me"><div style="display:inline-block;" class="avatar"><img src="https://avatars3.githubusercontent.com/u/4335753?v=3&amp;s=40" alt="100"></div><span>TaoAlpha</span></a><span>2016-01-12</span><span class="wordage">4304字</span><span class="readspeed">13 分钟读完</span></div><p>As I promised, I have been working on refactoring the feedpusher with pure JS/nodeJS from last week. Now I have set up the basic database struture and spider which has already been running for one week with 80 sites and 8k feeds stored into my mongodb on raspberry pi.</p>
<p>Today, I jsut set up a new process to crawl the updates which I called dynamic scheduling which means now the spider can decide whether this site needs to be recrawled this time or not by itself. Why? Most important reason is that as the number of sites goes bigger, the time it crawles all sites is longer, and also crawl every site everytime is not a good way.</p>
<p>Now I will explain how I do that with nodeJS.</p>
<h2 id="Theory"><a href="#Theory" class="headerlink" title="Theory"></a>Theory</h2><p>Our purpose is let the spider decide when to crawl a specific website/rss link, or in another word, everytime the spider runs, it needs to decide which website should be recrawled this time.</p>
<h3 id="What_data_I_have"><a href="#What_data_I_have" class="headerlink" title="What data I have"></a>What data I have</h3><p>Now I have and I can store some data into my database that may be good for this purpose, but we want to use as few as possible, so I decide to use these two attributes:</p>
<ul>
<li>lastCrawled: time I last crawled this website;</li>
<li>updateDuration: the duration between two continuous crawl of this site;</li>
</ul>
<h3 id="Dynamic_Scheduling"><a href="#Dynamic_Scheduling" class="headerlink" title="Dynamic Scheduling"></a>Dynamic Scheduling</h3><p>The <code>lastCrawled</code> is pretty simple and we don’t have a lot things can do with it. But the <code>updateDuration</code> is the core of the dynamic scheduling, since we can increase it and tell the spider that this site needs a longer duration before next crawling and vice versa.</p>
<p>So the basic idea is:</p>
<p><strong>The larger the <code>updateDuration</code> is, the longer the website get recrawled.</strong></p>
<h3 id="Rules"><a href="#Rules" class="headerlink" title="Rules"></a>Rules</h3><ul>
<li><strong>When to crawl</strong>: if current time minus the time <code>lastCrawled</code> is longer than the <code>updateDuration</code>, then the website needs to be recrawled;</li>
<li><strong>Motivate</strong>: if this round of crawling got any updates(new feeds) of this website, then we decrease the <code>updateDuration</code> of this website which is like motivating this website because of the updates;</li>
<li><strong>Penalize</strong>: if this round of crawling got no updates(new feeds) of this website, then we increase the <code>updateDuration</code> of this website which is like penalizing this website because of the later update than expected;</li>
</ul>
<h3 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h3><p>Based on these simple rules, the <code>updateDuration</code> of one site would be dynamic changing and will reflect the frequency of a website updates in some level.</p>
<h2 id="Coding"><a href="#Coding" class="headerlink" title="Coding"></a>Coding</h2><p>The coding part is pretty stright forward, but since the spider need get a lot of data from the mongodb, so you might need a lot promises to make sure the order of different processes is under your control.</p>
<p>I will put the Pseudocode here, if you are interested in the real code, you can check my <a href="https://github.com/taoalpha/feedpusher/tree/refactor" target="_blank" rel="external">feedpusher code refactoring repo</a> :)</p>
<h3 id="Pseudocode"><a href="#Pseudocode" class="headerlink" title="Pseudocode"></a>Pseudocode</h3><p>This is not a real pseudocode… but I believe you can bare with that :)</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// feed is the object of my core class I used for this spider</span></span><br><span class="line"></span><br><span class="line">feed.db.open((err, db) =&gt;&#123;</span><br><span class="line">  <span class="comment">// connect with database</span></span><br><span class="line">  <span class="keyword">var</span> allSites = [] <span class="comment">// store all sites we crawled this time in order to update the lastCrawled and updateDuration later</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// find all sites from the database</span></span><br><span class="line">  feed.findAllSites().then((data) =&gt; &#123;</span><br><span class="line">    <span class="keyword">var</span> curTime = moment()</span><br><span class="line">    <span class="comment">// Need use promise to make sure all finished before you update the lastCrawled and updateDuration</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">Promise</span>.all(data.filter( (v) =&gt; &#123;</span><br><span class="line">      <span class="comment">// filter all sites that the time from lastCrawled has passed the updateDuration</span></span><br><span class="line">      <span class="keyword">return</span> (((curTime - moment(v.lastCrawled)) / <span class="number">3600</span> / <span class="number">1000</span>) &gt; v.updateDuration)</span><br><span class="line">    &#125;)</span><br><span class="line">    .map( (v) =&gt;&#123;</span><br><span class="line">      <span class="comment">// crawl and store each feedUrl which is the link of the rss</span></span><br><span class="line">      allSites.push(v.feedUrl)</span><br><span class="line">      <span class="keyword">return</span> feed.crawler(v.feedUrl)</span><br><span class="line">    &#125;) )</span><br><span class="line">  &#125;)</span><br><span class="line">  .then( ()=&gt;&#123;</span><br><span class="line">    <span class="comment">// update the lastFCrawled for all sites</span></span><br><span class="line">    <span class="keyword">return</span> feed.updateCrawled(allSites)</span><br><span class="line">  &#125;,(reason)=&gt;&#123;</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="string">"Broken at crawler"</span>)</span><br><span class="line">    <span class="built_in">console</span>.log(reason)</span><br><span class="line">    db.close()</span><br><span class="line">  &#125;)</span><br><span class="line">  .then( ()=&gt;&#123;</span><br><span class="line">    <span class="built_in">console</span>.log(feed.stats)</span><br><span class="line">    feed.updateDuration(allSites).then( () =&gt; &#123;</span><br><span class="line">      <span class="comment">// Now update the updateDuration for all sites</span></span><br><span class="line">      db.close()</span><br><span class="line">    &#125;,(reason)=&gt;&#123;</span><br><span class="line">      <span class="built_in">console</span>.log(<span class="string">"Broken at updatedDuration"</span>)</span><br><span class="line">      <span class="built_in">console</span>.log(reason)</span><br><span class="line">      db.close()</span><br><span class="line">    &#125;)</span><br><span class="line">  &#125;,(reason)=&gt;&#123;</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="string">"Broken at updatedCrawled"</span>)</span><br><span class="line">    <span class="built_in">console</span>.log(reason)</span><br><span class="line">    db.close()</span><br><span class="line">  &#125;)</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>
<p>Yup! currently it works pretty good! :)</p>
<aside class="tipme special"><a href="/blog/tipme" class="tipme">If you like my work, buy me a soda or send me a book ! ^_^</a></aside></section><aside class="sidenav"><input type="text" placeholder="Enter to search" class="st-default-search-input searchbox"></aside><div class="relatedposts sidenav"><h2>Related Posts:</h2><ul class="article-list"><li><a href="http://taoalpha.me/blog/2015/12/07/tech-my-first-cli-tool-with-nodejs/">First CLI tool with NodeJS</a></li><li><a href="http://taoalpha.me/blog/2015/08/20/tech-raspberry-pi-as-nas-and-crawlers/">用 Raspberry Pi 做 NAS 和 采集器</a></li></ul></div><aside class="sidenav"><div class="recentposts"><h2>Recent Posts:</h2><ul class="article-list"><li><a href="http://taoalpha.me/blog/2016/01/09/read-javascript-coding-style/">JavaScript Coding Style</a></li><li><a href="http://taoalpha.me/blog/2016/01/06/oj-oj-leetcode-sort-3/">OJ LeetCode Sort 3</a></li><li><a href="http://taoalpha.me/blog/2016/01/05/oj-oj-leetcode-sort-2/">OJ LeetCode Sort 2</a></li><li><a href="http://taoalpha.me/blog/2016/01/04/oj-oj-leetcode-sort-1/">OJ LeetCode Sort 1</a></li></ul></div></aside><div class="comments"><div data-thread-key="2016/01/12/tech-dynamic-scheduling-crawler-for-feedpusher/" data-title="Dynamic scheduling crawler for FeedPusher" data-url="http://taoalpha.me/blog/2016/01/12/tech-dynamic-scheduling-crawler-for-feedpusher/" data-author-key="1" class="ds-thread"></div><script>var duoshuoQuery = {short_name:"taoalpha"};
(function() {
  var ds = document.createElement('script');
  ds.type = 'text/javascript';ds.async = true;
  ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
  ds.charset = 'UTF-8';
  (document.getElementsByTagName('head')[0] 
   || document.getElementsByTagName('body')[0]).appendChild(ds);
})();
</script></div></article><div class="notification fail hidden"></div><!-- jquery--><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.1.4/jquery.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-cookie/1.4.1/jquery.cookie.min.js"></script><script>(function(b,o,i,l,e,r){b.GoogleAnalyticsObject=l;b[l]||(b[l]=function(){(b[l].q=b[l].q||[]).push(arguments)});b[l].l=+new Date;e=o.createElement(i);r=o.getElementsByTagName(i)[0];e.src='//www.google-analytics.com/analytics.js';r.parentNode.insertBefore(e,r)}(window,document,'script','ga'));ga('create',"UA-46725017-2",'auto');ga('send','pageview');</script><script>(function(w,d,t,u,n,s,e){w['SwiftypeObject']=n;w[n]=w[n]||function(){
(w[n].q=w[n].q||[]).push(arguments);};s=d.createElement(t);
e=d.getElementsByTagName(t)[0];s.async=1;s.src=u;e.parentNode.insertBefore(s,e);
})(window,document,'script','//s.swiftypecdn.com/install/v2/st.js','_st');
_st('install','CUMLELEvkSRAFuVehSCm','2.0.0');</script><!-- main functions--><script src="/blog/js/functions.js"></script><script src="/blog/js/default.js"></script><script src="/blog/js/post.js"></script></body></html>